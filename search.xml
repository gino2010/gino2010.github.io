<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Consul的多实例注册问题]]></title>
    <url>%2F2018%2F11%2F09%2Fconsul%2F</url>
    <content type="text"><![CDATA[公司终于要重构一个非常古老的项目了（之前我建议了好多次，也讨论了好多次，这次终于动工了），将其按照微服务方式搭建，采用spring cloud框架（之前已经在其它项目中使用了很久）很期待此项目可以顺利实现，可以支撑未来的业务发展，然而这一次稍微来的晚了一些，我就要离开了。走之前我还是站好最后一班岗，把新版工程的微服务架构搭建一下，并实现统一gateway入口路由和oauth认证逻辑还有Member用户中心微服务中必要的接口，算是遗产了。按照我的习惯，只要是全新的项目，我将尽可能更新之前使用到的技术。由于之前我们使用的是Eureka作为注册服务，而它在2.0宣布闭源，这个对今后会带来什么影响未知，所以我决定将新版工程架构注册服务迁移到Consul。这不就遇到问题了…… 问题描述我有一个Member用户中心服务，当我在不同主机（不同ip地址）上运行两个Member微服务时，Consul中心只能看到一个服务实例。第一反应，What！？ 这个和我想象的完全不一样啊，这应该是默认功能啊，服务的多节点哪里去了！？如图：我运行了两个实例，但只能看见一个 我这里的consul用的是1.3版本 问题原因Consul团队具体怎么考虑这个实例名称生成规则的，我不是很清楚，但是问题就是因为它https://github.com/spring-cloud/spring-cloud-consul/issues/318一年多前开的issue竟然还没有关，问题就是instance id的默认组成规则是 application name - port没有ip地址，所以当我启动Member服务时，虽然在不同主机上，但是端口相同，所以instance id是一样一样的😂所以，我们只能看到最后启动的那个实例虽然下面回复中，中国朋友（推断）给出了明确的问题所在和建议的解决方法，然而Consul开发团队还是继续坚持他们的想法（或是spring cloud discovery包没有及时更新！？，issue没有关可能consul团队问题更多一些，人家spring团队也只是整合而已啦），额～～～为什么不改，没有理解 解决办法程序员DD给出了解决办法顺便提及一句，程序员DD非常不错，值得关注 随机端口方式我就不说了，这个不可取，我没有用。 直接final way，重新实现ConsulServiceRegistry 1234567891011121314151617181920/** * 调整consul服务注册实例名称 * * @author gino * Created on 2018/11/9 */@Configurationpublic class MyConsulServiceRegistry extends ConsulServiceRegistry &#123; public MyConsulServiceRegistry(ConsulClient client, ConsulDiscoveryProperties properties, TtlScheduler ttlScheduler, HeartbeatProperties heartbeatProperties) &#123; super(client, properties, ttlScheduler, heartbeatProperties); &#125; @Override public void register(ConsulRegistration reg) &#123; reg.getService().setId(reg.getService().getName() + "-" + reg.getService().getAddress() + "-" + reg.getService().getPort()); super.register(reg); &#125;&#125; 没有什么好解释的，在此启动就有两个服务了，如图两个服务，正常注册上了，红色区域就是我们要解决的问题最终结果。 总结除了Consul中的一些小改变，其实每次Spring Cloud的版本升级（当前使用的Greenwich.M1）都会这样那样的问题，我们需要慢慢踩雷，慢慢成长。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
        <tag>consul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Minsky Moment]]></title>
    <url>%2F2018%2F11%2F05%2Fminsky%2F</url>
    <content type="text"><![CDATA[明斯基时刻，最近刚刚了解到这个词，但听说已经火了一年了，我也算是后知后觉了。以下内容摘自百度百科和部分自身修改 基本定义明斯基时刻（Minsky Moment）是指美国经济学家海曼·明斯基 （Hyman Minsky）所描述的时刻，即资产价值崩溃的时刻。明斯基观点主要是经济长时期稳定可能导致债务增加、杠杆比率上升，进而从内部滋生爆发金融危机和陷入漫长去杠杆化周期的风险 简单说明斯基时刻表示的是市场繁荣与衰退之间的转折点。明斯基的观点简单明了：好日子的时候，投资者敢于冒险；好日子的时间越长，投资者冒险越多，直到过度冒险。一步一步地，投资者会到达一个临界点上，其资产所产生的现金不再足以偿付他们用来获得资产所举的债务。投机性资产的损失促使放贷者收回其贷款。“从而导致资产价值的崩溃。” 过程以现金流作为依据，海曼·明斯基将市场上的金融行为主体分为三类，其中风险最大的主体是高杠杆的银行和高赤字的政府部门。海曼·明斯基认为，资本主义经济追逐利润的本性和金融资本家天生的短期行为导致了资本主义金融业的不稳定 ，它是无法根除的，只要存在商业周期，金融业的内在不稳定就必然演化为金融危机，并进一步将整体经济拉向大危机的深渊 。在商业周期的上升阶段，内在危机会被经济增长所掩盖，但是一旦经济步入停滞甚至下降周期，矛盾便会迅速激化，高风险 的金融主体就会以变卖资产来偿还债务，也就是后来的学者所总结的明斯基时刻。 三阶段 第一阶段，投资者们负担少量负债，偿还其资本与利息支出均无问题。 第二阶段，他们扩展其金融规模，以致只能负担利息支出。 第三阶段，即旁氏骗局，他们的债务水平要求不断上涨的价格水平才能安然度日。 主要观点 在资本驱动的发展模式下，现代社会的金融周期和经济周期是重合的，信贷的扩张、收缩和经济的繁荣、衰退，是相互作用和加强的 信贷危机发生的临界点，也就是明斯基时刻，是信贷生产，消费和预期共同作用下的结果，它不以人的意志为转移 政府的逆周期宏观调控可以减轻这种周期的波动 摘自：香帅的北大金融学。 很巧，刚刚写了这个文章，香帅就发布一个关于此话题的节目 理论局限性明斯基的分析仅仅集中在“排他性的金融市场”，并没有很好地解释经济和金融之间的关系。明斯基的金融不稳定假设涉及的几乎完全是短期的周期性现象，只是一个“明斯基时刻”，而不是作为一种发展趋势。这个事实使他的分析更易被主流理论家们所接受——他们最关心的是证明经济会在政府的轻推下迅速反弹。 总结目前，我对此理解还停留在表面上。你认为我们在第几阶段了？ ……]]></content>
      <categories>
        <category>business</category>
      </categories>
      <tags>
        <tag>financial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes in Mac OSX 初探]]></title>
    <url>%2F2018%2F10%2F31%2Fkubernetes-in-mac-osx%2F</url>
    <content type="text"><![CDATA[折腾了许久，终于在我的苹果系统上安装上了kubernetes（k8s），可以开始实战了。 由于国内网络限制原因，你想安装Google资源下的k8s十分困难，你需要VPN，比较简单直接。开始在Ubuntu Server上折腾了一下，有点麻烦，而我主要是想体会一下使用效果，最后还是决定采用Mac OSX下Docker中的k8s试试，当然它的安装也需要VPN工具。 通过Docker内部自带的k8s安装，简单方便，不需要考虑minikube和virtual box或者其它虚拟化驱动（这里就直接跳过了，毕竟我也没有深入研究）安装后的k8s是但节点环境，所以默写细节功能与集群有差别，这个我需要慢慢体会。 启动Docker 下的 Kubernetes很简单，如图所示，enable apply running 查看基本信息查看版本，得到如下信息12345➜ ~ kubectl versionClient Version: version.Info&#123;Major:"1", Minor:"10", GitVersion:"v1.10.3", GitCommit:"2bba0127d85d5a46ab4b778548be28623b32d0b0", GitTreeState:"clean", BuildDate:"2018-05-21T09:17:39Z", GoVersion:"go1.9.3", Compiler:"gc", Platform:"darwin/amd64"&#125;Server Version: version.Info&#123;Major:"1", Minor:"10", GitVersion:"v1.10.3", GitCommit:"2bba0127d85d5a46ab4b778548be28623b32d0b0", GitTreeState:"clean", BuildDate:"2018-05-21T09:05:37Z", GoVersion:"go1.9.3", Compiler:"gc", Platform:"linux/amd64"&#125;➜ ~ kubectl config current-contextdocker-for-desktop 分别为Client 和 Server版本，其中Platform，client是darwin/amd64，Server是linux/amd64 123456➜ ~ kubectl cluster-infoKubernetes master is running at https://localhost:6443KubeDNS is running at https://localhost:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy➜ ~ kubectl get nodesNAME STATUS ROLES AGE VERSIONdocker-for-desktop Ready master 20h v1.10.3 本机只有一个节点 Dashboard管理上，目前我看到两种方式 通过kubectl命令的方式进行管理，主要维护方式 通过Dashboard进行管理， 主要是查看方式 安装Dashboard：1kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 查看Dashboard所在namespace中pod信息，需要指明namespace，否则查看的是default namespace下的pods：123456789➜ ~ kubectl get pods --namespace=kube-systemNAME READY STATUS RESTARTS AGEetcd-docker-for-desktop 1/1 Running 5 1dkube-apiserver-docker-for-desktop 1/1 Running 5 1dkube-controller-manager-docker-for-desktop 1/1 Running 3 1dkube-dns-86f4d74b45-r9w7b 3/3 Running 0 1dkube-proxy-mzrx2 1/1 Running 0 1dkube-scheduler-docker-for-desktop 1/1 Running 3 1dkubernetes-dashboard-7b9c7bc8c9-zkgzk 1/1 Running 2 1d 开启proxy，开始访问dashboard服务1➜ ~ kubectl proxy 浏览器打开：http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy 或者使用kubctl prot-forward 将dashboard pod运行的端口暴露出来进行访问1➜ ~ kubectl port-forward pods/kubernetes-dashboard-7b9c7bc8c9-zkgzk 8443:8443 --namespace kube-system 浏览器访问：https://127.0.0.1:8443，注意chrome提示你证书安全问题，直接unsafe方式访问吧 选择跳过，具体可以做什么，我还没有弄清楚，如果稍后了解，我再更新 我们可以看到纵览页面 这里截图是，我已经尝试部署了nginx pod，所以多了一些信息 用nginx部署 实战一下可以通过以下指令，部署一个pod12345➜ ~ kubectl run hello-nginx --image=nginx --port=80➜ ~ kubectl get deploymentNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEhello-nginx 1 1 1 1 1d 说到这里就有三个基本概念不得不说了，通过系统页面中给出的连接，我们针对nginx这个部署，看到以下这三个不同的内容这里我的理解尚浅，可能有描述不准确地方，欢迎告知 deployment 用于管理 replica sets 和 pods，您只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态。 replica set 副本，用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收。 pod 是kubernetes中你可以创建和部署的最小也是最简的单位。一个Pod代表着集群中运行的一个进程。pod里面饱含着docker的容器12➜ ~ docker ps | grep nginx66f968b67cf5 nginx "nginx -g 'daemon of…" 7 hours ago Up 7 hours k8s_hello-nginx_hello-nginx-6584d58b4c-gvk5b_default_f21fbf54-dce9-11e8-b679-025000000001_0 请注意这里的6584d58b4c-gvk5b，和对应的pod的名字中的编号一致 好了，这样几个基本概念就都连起来了。 怎么可以访问到这个nginx服务呢，这就需要引入service概念，我们将pod运行的实例暴露成服务1➜ ~ kubectl expose deployment hello-nginx --type=NodePort --name=hello-nginx-service 命令行可以通过以下指令查看1234➜ ~ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEhello-nginx-service NodePort 10.99.167.149 &lt;none&gt; 8010:32340/TCP 1mkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 2d 问题，是我并没有成功访问localhost:32340，这个我需要再看看。 安装 istio根据官方文档，我们可以很快部署istio podshttps://istio.io/docs/setup/kubernetes/quick-start/ 下载istio文件后，在其目录下运行1kubectl apply -f install/kubernetes/helm/istio/templates/crds.yaml 这部分我还需要继续实验下去，找时间继续更新。 总结kubernetes 的复杂程度超出了我对其的猜测，里面的知识点很多，需要花很多精力去深入进去，初步感觉还是挺有意思的。 参考网站：wilbeibi jimmysong]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 11 License]]></title>
    <url>%2F2018%2F10%2F31%2Fjava-11-license%2F</url>
    <content type="text"><![CDATA[晴天我的霹雳～～～～ 今天在MacOS下玩Kubernets，无意间发现Java 11的资源包变成的OpenJDK，去找Oracle版本时看到这个说明： Oracle’s Java 11 trap - Use OpenJDK instead! 文章重点就是，Java 11的License是商业授权，用于商业活动时，你是要付费的，不是免费的。 Oracle License原文可以参见这里：Oracle Technology Network License Agreement for Oracle Java SE Further, You may not: use the Programs for any data processing or any commercial, production, or internal business purposes other than developing, testing, prototyping, and demonstrating your Application; 就是这句话。 根据上文博主的说法，之前的license肯定都是免费的（我之前没有特别留意过），现在商业用途竟然需要收费了。 现在Google搜索引擎中搜索Java 11，可以看到Oracle 维护的open jdk 版本了。是的，它在维护openjdk版本地址在这里：https://jdk.java.net/11/ 当然文中博主还给出了其它的编译版本，https://adoptopenjdk.net 使用Java的小伙伴们，升级到Java11那是必然的，毕竟Java8支持终止时间已经明确了，只有Java11是最近的一个LTS版本然而，如果你还想免费用的话，请使用openjdk，别到头来，你开发了商业软件，最后要支付一大笔钱给Oracle钱多的土豪和拿Java写着玩（非商业软件）的人士可以忽略。 顺便说一句：作为国内的程序员，希望大家重视商业授权方式，开源 不等于 免费，一个是代码维护方式（开源协议也很多，请自行查找），一个是商业授权方式。因为，如果你想走的更远，你需要在规则体系之内，良好的意识也需要慢慢培养。共勉～]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Registration and Discovery - Spring]]></title>
    <url>%2F2018%2F10%2F29%2Fregister-discovery%2F</url>
    <content type="text"><![CDATA[关于Spring Cloud支持的注册发现服务，一直想了解一下对比情况，今天无意间发现这个对比文章，简单直接，可以给你一个直观的初步认识。转载原地址：服务发现比较:Consul vs Zookeeper vs Etcd vs Eureka这里仅贴出总结表格，稍作调整。其它内容请参见原文 Feature consul zookeeper etcd euerka 服务健康检查 服务状态，内存，硬盘等 (弱)长连接，keepalive 连接心跳 可配支持 多数据中心 支持 — — — KV存储服务 支持 支持 支持 — 一致性 raft zab raft — CAP ca cp cp ap 使用接口(多语言能力) 支持http和dns 客户端 http/grpc http（sidecar） Watch支持 全量/支持long polling 支持 支持 long polling 支持 long polling/大部分增量 自身监控 metrics — metrics metrics 安全 acl/https acl https支持（弱） — Spring Cloud集成 已支持 已支持 已支持 已支持，2.0闭源 感谢原作者的分享，并贴出与其文中一处不一样的观点，zookeeper的一致性协议不是Paxos，应该是ZAB。此观点依据：The core consensus algorithm of ZooKeeper is not Paxos 另外，euerka宣布2.0闭源后，目前来看Consul是替代euerka一个不错的方案。 CAP 简单解释 一致性(Consistency) (所有节点在同一时间具有相同的数据，客户端请求到同样的数据结果) 可用性(Availability) (保证每个请求不管成功或者失败都有响应) 分隔容忍(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作) CAP 不可能全都同时满足，这个已经被证明过了，这里先记住结论吧，具体解释网上文章很多。 Raft 演示相比Paxos，raft更容易被人理解和接受，看一下这个演示动画吧，简单直观。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
        <tag>CAP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Five Events of Scrum]]></title>
    <url>%2F2018%2F10%2F28%2Ffive-events%2F</url>
    <content type="text"><![CDATA[Scrum一个非常好的项目管理方式（方法论），我十分喜欢，但是，项目中使用需要很多客观条件支持，例如公司环境，队员素质等等。无论怎样，个人十分推荐在项目中尝试该管理方式。虽然，我不是Scrum Master（本人只有PMP证书），但是我一直对此深入学习，并尽可能多的将其应用到实际项目中。 今天我说一下Scrum中的五个事件 The Sprint 冲刺 一个敏捷迭代 Sprint Planning 敏捷迭代计划 Daily Scrum 每日Scrum Sprint Review 敏捷迭代评审 Sprint Retrospective 敏捷迭代回顾 The Sprint英文直译就是冲刺，其实我们可以将项目划分成多个sprint（冲刺），从而依高效、快速的方式完成整个项目。一个sprint周期一般为1个月（常见可以为2～4周）最终释放产品的增量（increment），在项目执行过程中，一个spring接着另一个sprintsprint过程中包括什么？ sprint包括下面四个事件，同时还包括具体开发工作。 sprint可以取消吗？ 当然可以，但只有产品经理有权限取消（终止）sprint，当然他要与必要的团队成员进行沟通。但是，sprint一般不会遇到取消，因为取消一个sprint通常是因为目标已经过时，但是sprint本身周期就很短，目的就是为了更好面对改变，所以一般不会遇到这个场景另外，一个sprint的取消将对团队和项目都有很不好的影响，甚至需要重新评估产品的Backlog，所以这个应避免出现。 在sprint中，我们应该 对sprint目标实现有影响的改变都不应该接受，实际上通常做法是freeze backlog后就不进行修改了，但是现在也有使用弹性冻结的思路 质量目标不能下降，降低sprint最终目标质量 随着项目的深入，产品经理和开发团队可能需要重新商讨项目范围，可能是因为任务难度超出了之前的预期。这也是弹性冻结的原因 Sprint Planning冲刺计划，或者是一个迭代周期的计划，通常表现形式为敏捷迭代计划会议，一般需要4个小时（一个小时对应一周）制定一个迭代周期内的相关工作，根据product backlog中的任务优先级形成sprint backlog。sprint planning 主要回答两个问题： 此sprint结束时将交付什么（increment）？ 为了正常交付，都需要做什么工作（backlog）？同时，也要明确，迭代时间、后续工作时间表、团队成员等会议一般需要包括： Scrum Master 宣布迭代时间表 阐明、更新product backlog，对业务的价值和优先级，并达成共识 选出并确定sprint backlog，团队共识迭代目标 拆解sprint backlog形成具体任务，每个任务应该小于2天 任务初步分配，可以使用看板进行后续跟踪和管理 Daily Scrum每日scrum，通常表现形式为 Daily Stand-up Meeting 日站立会，一般需要15分钟目的就是为了让组内成员互相知道都在做什么，有什么问题需要解决会议一般包括： 我昨天做了什么有利于sprint目标达成的工作 今天计划做什么有助于sprint目标达成 当前工作是否遇到问题妨碍目标达成 站会的站不是必须的，但一般为站着是为了提高效率，15分钟，大家直接沟通，不要阐述或讨论详细内容。 Sprint Review冲刺评审，通常在一个sprint周期的最后一天，评审此次sprint交付成果，通常表现形式为敏捷迭代评审会议，一般需要4个小时展示此sprint阶段的成果，进行评审、检查是否达到了预期的目标，参会人员应该包括项目团队成员和利益相关者，一般又产品经理来邀请会议一般包括： 完成什么，什么没有完成，阐述增量更新 开发团队总结哪些正在往好的方向发展，哪些遇到了问题，哪些问题得到了解决 后面要实现什么，这个可以作为下一个sprint迭代计划的输入 评审项目需求、预算、时间周期等，讨论产品任务清单，是否需要调整product backlog 此会议主要是总结迭代周期内工作完成情况 Sprint Retrospective冲刺回顾，通常在一个sprint周期的结束后某的一天（在review之后，在下一个planning之前），回顾此次sprint执行过程中的问题和好的经验总结，通常表现形式为敏捷迭代回顾会议，一般需要3个小时会议一般包括： sprint周期内，人员、流程、工具等表现如何 哪些做的好，哪些今后可以提升 创建后续可以提升的计划 此活动主要是总结团队Scrum经验，便于后面做的更好。 如有有问题，应该是整个团队负责，并寻找解决方法。 先写这些，今后再总结其它关键点]]></content>
      <categories>
        <category>management</category>
      </categories>
      <tags>
        <tag>scrum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Order Type]]></title>
    <url>%2F2018%2F10%2F26%2Forder-type%2F</url>
    <content type="text"><![CDATA[今天总结一下金融交易市场中订单类型（交易指令类型） 在金融市场中有很多的订单类型，在不同的市场（地区或者交易品种）针对不通的用户（散户还是券商等）可以使用的订单类型是不同的。订单类型的不同主要看券商和交易所是否支持（也有在交易客户端实现的，个人感觉那个就不要考虑了）这里仅仅将已知的订单类型列出，进行必要的总结。 买卖方向、开仓平仓这些内容直接跳过，我就不说了哈～ 先说从价格方面都有什么类型 市价单、限价单这两个放在一起说吧，应该是最常见和常用的两种类型，无论是股票、债券交易还是衍生品交易，我都可以看到这两种类型。 市价单（Market Order）：是以当时市场价格成交的订单，不需要自己设定价格，可以使得订单快速成交。限价单（Limit Order）： 需要指定成交价格，只有达到指定价格或有更好价格时才会执行。常为默认类型 很简单，很容易了解哈，市价单的心声，我就是要买入/卖出 价格不在乎，现价单的心声是：我先准备一下，价格到位，买入/卖出在执行 止损（盈）单止损单（Stop Order）是指在订单中设置止损价格，需要输入一个指定的止损价（Stop Price），一旦股价到达所设定的止损价，将会以市价单（Market Order）的方式成交。止损单和限价单的区别是低卖高买。国内少有做空机制，所以我们常见其在价格下跌时使用，其它市场可不一定哦 限价止损（盈）单限价止损单（Stop Limit Order）是止损单和限价单的组合即需要客户输入一个指定的止损价（Stop price，触发条件）和指定的限价（Limit Price 期望成交价格），一旦股价达到设置的止损价，将以限价单的方式下单 跟踪止损（盈）单跟踪止损单（Trailing Stop order） 止损触发条件，策略升级就是不限定止损价格本身，而是可以设置止损价格和市场价格之间的差价。差价的设置可以用金额，也可以用市价的百分比表示。 注意：这里的Stop Order其实是止盈止损都可以，在中国大家习惯的将其用于止损，所以叫法也就沿用了。个人一直有个感觉，金融术语最好看英文，中文翻译过来后很多本来很直接的描述变得让人难以理解或误解，再举个例子，例如：掉期（有机会再说了），外人看来，就是什么鬼～😛 在从时间和成交方式上都有什么类型 当日有效订单Day Orders，顾名思义，就是我们下的委托只在当日有效，闭市后委托自动撤销 GTC订单一直有效订单（Good Till Cancelled）字面意思交易下单人员不主动撤销此委托将长期有效，当然经纪商（Broker）通常限制GTC的最长有效时间，毕竟长期有效这是有成本的 IOC订单立即执行否则取消订单（Immediate Or Cancel），是委托指令尽可能多的成交（一次撮合判断），不成的部分就撤单。 FOK订单立即成交否则全部取消（Fill Or Kill），是指委托指令必须立即执行否则就全部取消（一次撮合判断），即不允许部分成交。 FAK订单立即成交并撤单（Fill And Kill），可以理解为FOK和IOC的组合体，是指委托指令必须立即执行尽可能多的成交（一次撮合判断），允许部分成交。同时，可以设定最小成交数量也可以不设定最小成交数量。如果设定最小成交数量，在限定价位下达指令后，若成交的申报手数高于或等于最小成交。 AON订单全部成交否则全部取消（All Or None），是指委托指令要么全部执行，要么全部取消，但可以等一等，直到撤单 再说一个，高级指令 冰山单冰山单（Iceberg Order），我们可以将一个大的委托发出，但在交易市场行情或盘口数据中逐步释放成交量和委托数量，这种单子在实际操作场景中是有战术意义的，隐藏真实的交易规模。这个不展开说了，单独都可以写一篇博客了。 好了，目前就这些类型吧，如果后期遇到新的，我再更新。 当然，我们目前实现的订单类型也很有限。]]></content>
      <categories>
        <category>business</category>
      </categories>
      <tags>
        <tag>financial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Transaction]]></title>
    <url>%2F2018%2F10%2F25%2Ftransaction%2F</url>
    <content type="text"><![CDATA[事务，很基础的概念，但有很多细节是大家忽略的或者平时很少注意到的。这里总结一下：实验工程 （这工程的实验代码尚不完整，再更新看心情了😛） ACID先说ACID，工程里说自查度娘，还是算了吧，我还是解释一下吧，度娘不靠谱 原子性（Atomicity） 操作原子性，同一个事务中要么所有操作都执行，要么都不执行。好理解 一致性（Consistency） 一致性（经常和原子性混），原意是数据库从一个状态转换为另一个状态（完全不知所云哈？）。其实说的是写入数据必须复合数据库的相关约束，包括限制、级联、触发等（还不明白？）举个例：A外键关联B，一个事务试图插入B数据，但不插入与其关联的A记录，当然这是非法事务，它违反的就是一致性原则。 隔离性（Isolation） 隔离型决定了，是否可以避免脏读、不可重复读、幻读，这个下面来深入说明，这个也很少有人关注过 持久性（Durability） 持久性，这个强调的是commit后不要存在内存中，commit要求写入硬盘，当然也就不丢了 参考 单说隔离性隔离级别 解决脏读取、重复读、幻读 DEFAULT：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是：READ_COMMITTED。 READ_UNCOMMITTED：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读和不可重复读，因此很少使用该隔离级别。 READ_COMMITTED：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。 REPEATABLE_READ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。即使在多次查询之间有新增的数据满足该查询，这些新增的记录也会被忽略。该级别可以防止脏读和不可重复读。 SERIALIZABLE：所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 脏读 不可重复读 幻读 READ_UNCOMMITTED ✅ ✅ ✅ READ_COMMITTED ❎ ✅ ✅ REPEATABLE_READ ❎ ❎ ✅ SERIALIZABLE ❎ ❎ ❎ 脏读（Dirty Read）：A事务进行中读到了B事务尚未commit的数据 不可重复读(Fuzzy/Non-Repeatable Read) : A事务进行中第一次读取，B事务提交更新数据，A事务再次读取，数据不一致 幻读（Phantom Read）：A事务读取了M跳数据，B事务插入数据N条提交，A事务再次读取发现为M+N条 个人推断，事务隔离级别应该和数据库锁相关，不可重复读需要行级锁，而幻读需要表级锁。这个需要进步一验证 注意：这里说的都是数据库自身问题，如果在开发过程中，我们使用的ORM框架自身还有数据对象状态问题，例如：临时态、持久态、游离态。这些不正常处理可能会造成事务内操作出错。 解决程序或数据库中类似的数据冲突问题，我们需要考虑程序锁或数据库错（无论怎样性能都将受到影响，需要合理设计），或者CAS操作（性能好，但是应用场景受限），这又将是个大话题，稍后再阐述吧。 进阶阅读这个文章比我说的详细多了，pingcap团队的。 推荐阅读。 后续近期公司需要将一套老系统进行微服务拆分并重构，花了一天的时间深入梳理一下ACID BASE 和 CAP，这些概念之前虽然都看过，但是现在再看又有更为深刻的理解了，温故而知新啊这个部分内容专业、庞大又复杂，还是先推荐几篇别人的文章吧，如果可能，稍后再总结自己的想法CAP、ACID、BASE理论及NWR实践策略详解分布式服务化系统一致性的“最佳实干”]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>db</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Distributed Lock]]></title>
    <url>%2F2018%2F10%2F22%2Fdistributed-lock%2F</url>
    <content type="text"><![CDATA[分布式锁，在微服务，多服务器水平扩展以及高并发的场景下，要保证共享资源正确处理，这个锁很重要。我了解到了三种实现方式： 数据库方式，基于主键唯一性约束或行级锁实现 Zookeeper实现，基于其临时有序节点实现 Redis方式，基于setNX操作实现 三种方式各有优缺点，在恢复此博客之前我已经实现了基于Redis版本的分布式锁，现在把另外两种加以实现，并做相应的对比。 Mysql数据库方式实现分布式锁，主要用三种形式： 乐观锁，version，通过where条件中的version决定是否可以更新成功，从而获得锁 主键唯一约束方式，是否可以正常写入数据，从而获得锁 数据库自身锁 for update 来决定是否可以获得锁 这里我们不讨论乐观锁，为了和zookeeper、redis的锁做对比，这里采用使用主键唯一约束方式实现锁。 创建锁表，其中method_name需要索引并唯一，时间默认1234567CREATE TABLE method_lock( id int PRIMARY KEY NOT NULL AUTO_INCREMENT, method_name varchar(64) NOT NULL, update_time timestamp not null default current_timestamp on update current_timestamp);CREATE UNIQUE INDEX method_lock_method_name_uindex ON method_lock (method_name); 关闭自动提交，开始手动提交，保证事务中的操作原子性1connection.setAutoCommit(false); 获得锁，两个操作，删除超时的锁（超时自动释放机制），插入数据获得锁123456789PreparedStatement preparedDelete = MySQLConfig.connection.prepareStatement(clearSQL);preparedDelete.setString(1, name);preparedDelete.setInt(2, 3);preparedDelete.executeUpdate();PreparedStatement preparedInsert = MySQLConfig.connection.prepareStatement(insertSQL);preparedInsert.setString(1, name);MySQLConfig.connection.commit(); 如果提交失败，进行重试，设定时间间隔和重试次数1public static boolean getLockTimes(String name, int times, int interval) 释放锁，直接删除锁占有的记录1234PreparedStatement preparedDelete = MySQLConfig.connection.prepareStatement(deleteSQL);preparedDelete.setString(1, name);preparedDelete.executeUpdate();MySQLConfig.connection.commit(); Zookeeper不重复造轮子了，轮子原理简单说一下吧，两种实现方式： 固定节点，利用文件名称唯一性，谁可以创建create指令该节点，谁就获得锁，类似redis中的获取锁操作，删除节点释放锁，其它watch该节点 利用zookeeper中临时有序节点，尝试获得锁，如果当前线程申请到的节点序号为最小，则获得锁，否则监听前一个序号等待状态改变，然后再次判断。 建议大家，如果有轮子就不要自己造了，因为绝大多数情况下，我们造的不如已有的轮子。所以，实验使用成熟的CuratorFramework，创建InterProcessMutex锁对象 通过acquire尝试获得锁，其中3s为可以接受的尝试获得锁的时间，如果太短，可能资源竞争激烈导致获得不到锁，而返回false，所以考虑了重试机制。1mutex.acquire(3, TimeUnit.SECONDS); 释放锁，事务处理完毕后，需要释放锁，最好判断一下，是不是当前线程拥有这个锁，然后尝试释放。1234if (mutex.isOwnedByCurrentThread()) &#123; mutex.release(); log.info("release lock....");&#125; 如果按照网上原理介绍来看，其判断是自增序号的最小值为获得锁，那么其应该是是一个公平锁，这一点我需要再进一步验证一下。 RedisRedis分布式锁，redis官网有相应的文章阐述，这里相当于模仿着造了一个轮子 首先实现一个redis实例即单节点的例子，这个是基础。通过多线程方式模拟测试，实际应用不应该是多线程环境，否则使用线程同步相关技术就好了。其次，初步实现了RedLock方式，用于多个Redis节点，增强其稳定性。但实际使用可能还是单节点比较多，需要考虑锁失效的弥补方式。 这里的set方法是关键，其保证了判断是否存在以及设置锁值和有效时间一系列操作的原子性，否则这个分布式锁的实现是不成立的。123456String res = resource.set(lockKey, uuid, "NX", "PX", keyExpire);if ("OK".equals(res)) &#123; resource.close(); log.info("Get lock, uuid: &#123;&#125;", uuid); return uuid;&#125; 设置成功，则获得锁，否则失败。其中设置的值为uuid随机数，所以这个理论上是非公平锁 释放锁，即删除值，这是需要watch这个值，并在事务内将其删除12345678910111213resource.watch(lockKey);if (uuid.equals(resource.get(lockKey))) &#123; Transaction multi = resource.multi(); Response&lt;Long&gt; del = multi.del(lockKey); multi.exec(); if (del.get() == 1) &#123; log.info("Release lock, uuid: &#123;&#125;", uuid); retFlag = true; &#125; else &#123; log.info("Release lock, failed!"); &#125; multi.close();&#125; 当redis有多个节点时，我们需要奇数个点来按照多数原则判断是否获得了锁。程序中通过一个redis中的不通DB来模拟的。有效时间内，节点数大于一半，就认为获得成功，否则失败12345678if ((passNode.get() &gt;= nodes / 2 + 1) &amp;&amp; (end - start) &lt; keyExpire) &#123; log.info("Get RedLock uuid &#123;&#125;, pass node:&#123;&#125;", uuid, passNode.get()); return uuid;&#125; else &#123; log.info("Get RedLock failed"); releaseLock(lockName, uuid); return null;&#125; 总结无论什么怎样实现分布式锁，都需要考虑一下内容： 判断锁是否存在和设置锁值，两步需要原子性 考虑申请锁时，申请的超时时间和尝试次数，具备非阻塞特性 需要考虑锁的正常销毁方式，主动删除锁 需要考虑锁的异常销毁方式，例如有效时间或者回话断开删除 适当考虑重入特性 使用总结： mysql 利用数据库特性还是很方便的，性能有限 zookeeper实现应该是非常严谨的，但是性能一般 Redis虽然实现上还存在争议，但是性能很好 性能: 缓存 &gt; Zookeeper &gt; 数据库可靠性: Zookeeper &gt; 缓存 &gt; 数据库 实现复杂度，看你对谁熟悉了，我个人感觉得差不多。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>zookeeper</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper]]></title>
    <url>%2F2018%2F10%2F18%2Fzookeeper%2F</url>
    <content type="text"><![CDATA[近期在做MQ的实验，所以又接触了一下Zookeeper，之所说又是因为之前碰到过，但是只是用而已没有了解过一些细节。 Zookeeper 做什么？引用官方原话：ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. 他可以提供高可靠的分布式协调服务，包括中心化配置服务等。之前我用它做了什么，注册发现服务器，你是不是也是用了这个功能，但是具体怎么实现的，Spring Cloud都已经实现了，没有深入关心过。 这个文章我们补一些必要的知识，更加深入的了解Zookeeper。 Zookeeper 怎么玩？首先，简单说他好似一个文件目录，是一个可以存储数据的服务器，这里我们先忽略其集群中的一些特性（选举制度等），我们看它对外可以提供什么。 它内部有类似文件目录的结构，节点称之为znode 文件结构可以存储数据，可以想象为目录结构的Redis 节点数据大小有限，不可以超过1M 可以通过接口获得数据，这也是我们用其分布式协调服务的关键 补充，数据过大怎么办，目前了解到的有两个思路，没有实验过： 使用专业的分布式存储HDFS等 使用Redis，然后zookeeper记录索引就好了 命令行两种形式，分别对应查看管理 服务器状态和内部存储。 查看管理服务器状态，可以通过telnet 和 nc发出指令，一般使用nc比较方便（具体命令参考网上信息）1234567891011echo stat| nc 127.0.0.1 2181 # 来查看哪个节点被选择作为follower或者leaderecho ruok| nc 127.0.0.1 2181 # 测试是否启动了该Server，若回复imok表示已经启动。echo dump| nc 127.0.0.1 2181 # 列出未经处理的会话和临时节点。echo kill | nc 127.0.0.1 2181 # 关掉serverecho conf | nc 127.0.0.1 2181 # 输出相关服务配置的详细信息。echo cons | nc 127.0.0.1 2181 # 列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。echo envi | nc 127.0.0.1 2181 # 输出关于服务环境的详细信息（区别于 conf 命令）。echo reqs | nc 127.0.0.1 2181 # 列出未经处理的请求。echo wchs | nc 127.0.0.1 2181 # 列出服务器 watch 的详细信息。echo wchc | nc 127.0.0.1 2181 # 通过 session 列出服务器 watch 的详细信息，它的输出是一个与 watch 相关的会话的列表。echo wchp | nc 127.0.0.1 2181 # 通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径。 如果提示：xxx is not executed because it is not in the whitelist.请在conf/zoo.cfg中添加：14lw.commands.whitelist=* #或者具体指令stat, ruok 查看管理服务中的节点信息，需要zkCli命令（客户端），这个在zookeeper所对应的bin目录下有，zkCli进入后，随便敲点啥，你可以看到如下：1234567891011121314151617181920212223242526272829[zk: localhost:2181(CONNECTED) 0] ?ZooKeeper -server host:port cmd args addauth scheme auth close config [-c] [-w] [-s] connect host:port create [-s] [-e] [-c] [-t ttl] path [data] [acl] delete [-v version] path deleteall path delquota [-n|-b] path get [-s] [-w] path getAcl [-s] path history listquota path ls [-s] [-w] [-R] path ls2 path [watch] printwatches on|off quit reconfig [-s] [-v version] [[-file path] | [-members serverID=host:port1:port2;port3[,...]*]] | [-add serverId=host:port1:port2;port3[,...]]* [-remove serverId[,...]*] redo cmdno removewatches path [-c|-d|-a] [-l] rmr path set [-s] [-v version] path data setAcl [-s] [-v version] path acl setquota -n|-b val path stat [-w] path sync pathCommand not found: Command not found ?[zk: localhost:2181(CONNECTED) 1] 我主要使用了： ls 显示znode crate 创建znode，并设置初始内容 get 获取znode内容 set 修改znode内容 delete 删除znode 退出客户端： quit 实验工程测试工程地址 ，开发环境： mac os x &amp; idea &amp; gradle spring cloud &amp; zookeeper config &amp; discovery zookeeper 3.5 in docker 请注意，其中使用的最新版的curator包只支持zookeeper3.5 关键代码通过CuratorFramework 设置或读取zookeeper中的节点123456789curatorFramework.blockUntilConnected();Stat stat = curatorFramework.checkExists().forPath("/test");if(stat==null) &#123; curatorFramework.create().creatingParentsIfNeeded() .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) .forPath("/test", "data".getBytes());&#125;byte[] bytes = curatorFramework.getData().forPath("/test");log.info("path test:&#123;&#125;", new String(bytes)); 将zookeeper作为配置中心，通过value注解获取zookeeper中的配置信息，这样可以做到在不重新启动服务的情况下，动态加载配置信息代码需要： 12@Value("$&#123;zc&#125;")private String zc; 也可以将配置信息加载到一个对象上，并实现动态刷新123456789@Component@RefreshScope@ConfigurationProperties("demopro")public class DemoProperties &#123; private String key; private String value; //get set&#125; 配置文件需要： 12345678application: name: zookeeperDemo config: enabled: true root: /demo defaultContext: context profileSeparator: ',' 因为spring cloud支持active profile，所以对应的zookeeper的znode路径可以是： /demo/zookeeperDemo,default /demo/zookeeperDemo /demo/context,default /demo/context 具体到zc这个配置，对应在default下的全路径是：/demo/zookeeperDemo,default/zc，你可以在zookeeper中创建一个： 1create /demo/zookeeperDemo,default/zc data 具体到DemoProperties配置对应在default下的全路径是：12create /demo/zookeeperDemo,default/demopro.key prokeycreate /demo/zookeeperDemo,default/demopro.value provalue 以上为工程实验的关键点，具体工程参考源码，工程后续可能还会更新。 吐槽这些问题不是针对zookeeper，只是借此表达一下，其它国内实例代码也有类似的普遍现象 Curator的使用，国内几乎没有，说明大家几乎没有尝试自己去使用zookeeper的存储功能，都是人云亦云般的介绍功能 查看中心化配置，路径的写法几乎都没有验证，实例代码几乎都不起作用，你们贴别人代码时不实验一下吗？ 请大家（同行）做到，我写的，我贴的，我抄的代码，我至少都实验过，不要传播错误的代码。共勉！]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Message Queue 初探]]></title>
    <url>%2F2018%2F10%2F16%2Fmq%2F</url>
    <content type="text"><![CDATA[消息队列（MQ），平时经常遇到的中间件技术。个人工作中已经使用的RabbitMQ，最近开始使用Kafka，因此也打算把ActiveMQ实验一下。所以本文章将围绕这三个MQ产品进行相应的实验。 创建实验工程三个MQ实验工程地址 工程使用spring boot创建，所有实现都将基于spring全家桶，已经很完毕了，拿来直接用吧。 为了后续实验方便，分别多个mq的producer和consumer工程 使用gradle管理项目结构 使用docker搭建测试所需要的服务器，文件可以参考，实际部署环境有所调整 Kafka首先实验了Kafka的生产和消费基本代码procuder：1this.kafkaTemplate.send(topic, message); consumer:1@KafkaListener(topics = "$&#123;app.topic&#125;") 运行说明 使用三个kafka broker 节点，使用docker-compose对应的service实现 创建topic，使用三个分区和两个副本 使用idea，运行工程，配置多个运行实例 特性总结 一个分区对应一个消费者 一个分区内消息顺序消费 分区和和服务器应该成倍数关系，保证分区均匀分布 副本数量应该小于服务器数量，当可用分区失效时，从副本中选出leader，成为新的可用分区 节点高可用性，消费服务瞬间切换 保存近期所有数据，通过offset可以获得任意位置的消息 是否允许自动创建topic需要在kafka中配置 ACK MODE 和 Commit需要注意ack mode和 commit，此项影响数据的刷盘机制。根据实际情况选择 RECORD 逐笔ack并提交 BATCH 一个poll周期进行ack提交 TIME 通过设置ackTime定时提交 COUNT 通过设置ackCount累计数量提交 COUNT_TIME 同上组合，哪个复合执行哪个 MANUAL 手动方式生成ack，批量提交 MANUAL_IMMEDIATE 手动方式生成ack并立即提交 广播与点对点广播有时也叫pub和sub，就是一个topic，多个订阅者。每个订阅者都会收到相同的消息，消息被多次消费。点对点，一个topic中的消息对应一个消费者，消息只会被消费一次 在Kafka的系统中，如何区分以上两种方式，是通过consumer group实现的。 多个消费者在一个consumer group中，那么他们就是一个消费整体，消息只会被一个具体的消费者消费一次如果想多个同时消费，那么需要多个consumer group。这样来看consumer group需要与具体服务对应，一般一个独立的服务需要消费一次消息。 总的来说，体会到了大家喜欢的它原因，具体一些实验后续将深入。建议参考阅读 ActiveMQ每个MQ中的术语大同小异，但又十分不统一，随着遵循的协议不一样，让我们看看ActiveMQ，它使用JMS协议 Queue 和 TopicTopicsIn JMS a Topic implements publish and subscribe semantics. When you publish a message it goes to all the subscribers who are interested - so zero to many subscribers will receive a copy of the message. Only subscribers who had an active subscription at the time the broker receives the message will get a copy of the message. QueuesA JMS Queue implements load balancer semantics. A single message will be received by exactly one consumer. If there are no consumers available at the time the message is sent it will be kept until a consumer is available that can process the message. If a consumer receives a message and does not acknowledge it before closing then the message will be redelivered to another consumer. A queue can have many consumers with messages load balanced across the available consumers. 这里的 topics 类似kafka中的广播，pub/sub 模式，queue是队列是点对点模式。他的主要区别是，消费方式的确定不是在consumer设置，而是在MQ Server中设置消费性质上同上： topic的消息会多个消费者同时消费，但并不做消息堆积，没有之前的消息 queue消息只有一个消费者消费，并做消息缓存堆积，直到消费为止 同时queue的消费者是负责均衡的会分摊消息队列的中的数据，但是不能保证按顺序执行 关键代码消费端1234567891011121314151617@Beanpublic JmsListenerContainerFactory&lt;?&gt; queueListenerFactory(ConnectionFactory connectionFactory, DefaultJmsListenerContainerFactoryConfigurer configurer) &#123; DefaultJmsListenerContainerFactory factory = new DefaultJmsListenerContainerFactory(); configurer.configure(factory, connectionFactory); return factory;&#125;@Beanpublic JmsListenerContainerFactory&lt;?&gt; topicListenerFactory(ConnectionFactory connectionFactory, DefaultJmsListenerContainerFactoryConfigurer configurer) &#123; DefaultJmsListenerContainerFactory factory = new DefaultJmsListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); configurer.configure(factory, connectionFactory); factory.setPubSubDomain(true); return factory;&#125; 通过spring boot 配置文件可以指明消费方式，是topic还是queue，但是只能只一种。为了同时支持两种方式，我么需要声明JmsListenerContainerFactory。是否开启pub sub domain，决定是queue还是topic1factory.setPubSubDomain(true); 同时配合JmsListener注解，就可以指明消费方式了。如果指明的消费方式与ActiveMQ所创建的queue或topic不一致，则消息不能正常消费。1@JmsListener(destination = "$&#123;app.queue&#125;", containerFactory = "queueListenerFactory") 生产端123456789@Bean public Queue queue() &#123; return new ActiveMQQueue(queueName); &#125; @Bean public Topic topic() &#123; return new ActiveMQTopic(topicName); &#125; 通过不通类型指明是topic还是queue 运行说明同样创建多个运行实例，来观察消费情况 观察ActiveMQ管理后台，你可以看到相关的配置信息 特性总结 简单，两种消费模式非常清晰，没有复杂的系统结构 自带管理后台还算好用 还需要深入体会其一些参数设置，初步感觉中规中矩没有什么好说的。😜 RabbitMQ最后说熟悉的RabbitMQ吧。我很喜欢RabbitMQ，功能上丰富，性能不错，相比ActiveMQ，我更喜欢RabbitMQ吧。当然具体使用，还是要分应用场景。 基本概念RabbitMQ中有几个主要概念，和其它MQ的定义有些区别，其为AMQP协议 Exchange 交换机，用于消息的分发，如果不指定则会使用默认的 Queue 队列，实际缓存数据的消息队列，可对应多个消费者 Topic 主题，消息可以有主题，用于exchange分配消息是的判断依据 virtual host 虚拟路径，可以创建虚拟路径将相关配置分开并设定特定用户用于访问控制 消费方式RabiitMQ的消费方式和灵活度上应该是这三者中最好的，并且官方给出了详细的实例说明，超有爱❤️当然由于模式多，它也就是最复杂的。官方给出的六个实例，这里简单说一下，具体代码看原址 Hello World 最普通的生产消费代码 Work Queue 默认exchange，工作队列，一个队列被多个消费者消费，且一个消息只消费一次 Publish/Subscribe 发布订阅，通过exchange Fanout模式进行队列分发，实现一条消息可以被多个消费者消费 Routing 路由方式，通过exchange和routing key指定消息路由到具体的队列别特定的消费者消费 Topics 主题方式，通过exchange和topic比配规则指定消息路由到具体的队列别特定的消费者消费 RPC 通过消息队列实现RPC调用过程 Exchange 方式： direct exchange 直接点对点 fanout exchange 全体广播 topic exchange 主题广播 headers exchange 还没有用过 system exchange 还没有用过 关键代码生产端123456789101112131415// 声明queue@Beanpublic Queue queue() &#123; return new Queue(queueName);&#125;// 声明fanout exchange@Beanpublic FanoutExchange exchange() &#123; return new FanoutExchange(broadcast, false, true);&#125;// 声明 queue与exchange的绑定关系@BeanBinding binding1(Queue queueBroadone, FanoutExchange exchange) &#123; return BindingBuilder.bind(queueBroadone).to(exchange);&#125; 消费端1234@RabbitListener(queues = "$&#123;app.broadone&#125;")public void recevieOne(String message) &#123; log.info("consumer receive broadcast one: &#123;&#125;", message);&#125; 运行说明这里我只做消息在多消费者下顺序消费观察和广播观察，其它实例参考官网代码吧，没有必要重复了。 一个生产者、一个queue、多个消费者，和ActiveMQ queue方式，观察效果一致： 多个消费者的消息分摊，如果每条消费执行时间差异较大，消费顺序不保证一致 消费退出，另一个消费者会接替未完成的消息工作 广播消息默认堆积，其本质还是消费队列，不能多个消费者消费一个queue实现pub/sub 同样创建多个运行实例，来观察消费情况 管理后台可以看到的信息 特性总结 功能多，使用灵活 AMQP，性能不错 管理后台方便 实验总结 如果你需要消息顺序消费、分布式存储的高可用性，指定消息位置再次消费，较高的吞吐 —— Kafka 如果你要消息正常消费，无顺序要求、无特殊路由要求。广播消费时，多个消费者可以监听一个queue的方式完成 —— ActiveMQ 如果你要适合多种消息根据自定义规则（通配符等）路由道不同的消息队列，或兼容不通场景，希望广播消息有堆积不丢失 —— RabbitMQ 以上MQ都还有很多配置参数应对不通的应用需求，可能通过配置实现默认不支持的功能，具体使用情况，如果以后遇到我再单独说明。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>middleware</tag>
        <tag>Kafka</tag>
        <tag>ActiveMQ</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack 从入门到继续]]></title>
    <url>%2F2018%2F10%2F11%2Fopenstack%2F</url>
    <content type="text"><![CDATA[近期给自己挖的技术坑有点多，我忍不住再挖一个，最近又了解到了云服务的相关技术（算是技术储备吧） What is OpenStack?OpenStack是被广泛使用的云操作系统，它管啥，如图： Components所有组件详见：网站列出的所有组件 找几个介绍多的，简单说一下 HORIZON前端Web管理界面，包括Dashboard控件展示，便于用户对相关服务进行操作 NOVA计算服务,应该是管理计算资源的组件，提供相应的管理服务 NEUTRON提供云计算的网络虚拟化技术，为OpenStack其他服务提供网络连接服务，实现SDN SWIFTSwift是高可用、分布式、最终一致性的对象存储，具体文件对象 CINDER块存储服务，更像是硬盘，数据卷 KEYSTONE认证服务，支持LDAP Oauth OpenID等 GLANCE镜像服务，不通的操作系统镜像 HEAT编排架构资源 不通场景中需要不通的服务来构建，可以参考sample configurations What is the relationship between Docker and OpenStack Docker 主要针对 Paas 平台，是以应用为中心。 OpenStack 主要针对 Iaas 平台，以资源为中心，可以为上层的 PaaS 平台提供存储、网络、计算等资源。 这个话题先开个头，后面有机会再继续深入吧。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>openstack</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的OKR(2018.10)]]></title>
    <url>%2F2018%2F09%2F29%2Fokr%2F</url>
    <content type="text"><![CDATA[最近重温吴军老师的硅谷来信，想起了Google人员采用的目标管理方法OKR(Objectives and Key Results)全称为“目标和关键成果”。吴军老师在其硅谷来信114封信中分享了这个方法（不仅可以用于工作也可以用于自己的生活）并结合他个人的2017年目标做了阐述。这也使我产生了同样念头，用OKR方式管理我自己的目标。 初衷和理解我希望我可以不断进步，可以用更为有效方式使自己获得成长，而对OKR目标管理初步了解下来，我认为是合适我的想法。 OKR的目标制定一般是需要一些挑战性的，这样才能达到自我提升的目的，我也将逐步加大目标达成的难度，同时开始也可能会有些设定不合理。 其次，目标不能太多，否则难以集中注意力，一般在5个以内。 时间不易太长或太短，太短难以实现有挑战性的目标。太长过程有可能有太多不确定性的事情打破原有的计划，使得制定意义减弱。所以借鉴Google的做法，制定季度OKR。 季度 OKR正好九月底了，10月开始正好是2018年最后一个季度，也将是我的第一个OKR季度。 目标一 英语流利说学习达标近期参加了英语流利说付费课程，提升自己的口语能力，也是近期主要的学习内容。 连续打卡，每天学习时间平均不低于70分钟 所有课程分数不低于3颗星🌟（满星4颗） 流利说评定的口语等级上升一级。（按照当前进度应该可以做到） 除此之外，我还在得到APP上购买了《吴军的谷歌方法论》和《香帅的北大金融学课》这个学习也会保持，但这个基本没有什么挑战了。 目标二 深入一个计算机中的流行技术学习掌握并深入一个流行的计算机技术 深入了解和掌握 Kubernets 这是我最近最想掌握的一个技术。除此之外我还会不定期更新个人github中的一些小例子，来记录我零碎的技术总结。 目标三 看完一本非计算机类书我的书单已经列了很久、很多了，是需要花些时间看看书了 看完赫拉利的《今日简史》，看看都提出了什么问题 因为时间原因，这个目标可能最难完成。之前把赫拉利的《人类简史》看完了，《未来简史》看了一部分，看不下去了，再找时间吧。而《今日简史》中的当今问题使我比较感兴趣的，想读读，也算是把赫拉利的著作都看了看。题外话，近半年还看了两个小说《副本》和《头号玩家》这两个都有对应的影视作品，感兴趣的朋友可以看看，纯当消遣。 目标四 锻炼身体，保持身体健康天气转凉，终于可以锻炼身体了，天气热时真的是懒得动，极爱出汗的我更喜欢冬天。 每周用Keep（一个健身APP）不少于2次， 每周 跑步不小于3公里（我知道这个目标定低了一些，我需要先适应一下） 每日睡眠（包含午休）不少于7个小时。 这个估计难度也不小，我可以支配的时间太有限了，现在晚上睡眠平均小于6小时，很少运动，这是我精力有些疲倦，所以需要改变一下。 目标五 陪孩子Family is first，我一直提醒自己，孩子又是其中最关键的。 每日至少用半个小时与孩子做有效沟通，了解一天的情况或讨论一个小事情 平均每周用完整的3个小时陪孩子做些有意义或者有趣的事情，包含户外活动等。 五个目标，不多不少，希望可以在下面一个季度都可以做到。 年度 OKR索性再列几个年度的OKR吧，希望后面一年可以做到 目标一 付费课程学习 购买付费课程，全年不少于三门，并完成学习内容 目标二 读书 读非计算机类、非小说类书，全年不少于5本。 目标三 英语口语 完成流利说口语付费课程内容 按照流利说标准，达到Level 6级或以上 当然还有工作上的一些目标，这里就详述了。 列出这些和大家分享，同时也是督促自己，如果你也感兴趣，不妨试试。如有好的建议和想法欢迎留言，谢谢！ I wanna improve myself, better late than never. OKR参考文章]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>OKR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 11]]></title>
    <url>%2F2018%2F09%2F27%2FJava-11%2F</url>
    <content type="text"><![CDATA[昨天得知Java 11发布。请允许我说：我的天啊，竟然Java 11了。 连Java 8还没有完全熟练使用的我，一时间有点恍惚。 近期，Java更新如此频繁，让人有点应接不暇，新的features层出不穷，而我们又真的学习使用了几个呢？ 反正我只用了一小部分吧。这里不列举Java 8之后各个版本中的features了，大家可以自行Google。 这里只想说：Java作为生命力极强的大型服务类开发语言，Oracle好像在给其注入新的活力，也在打破Java原有的墨守陈规。我们可以看出它的很多新特性是源于这个时代技术的发展，也有很多借鉴了其它语言的特性，在”提(da)升(po)”原有的语法结构方式给用户带来新的开发体验。这也是在满足新加入Java世界的开发者？ 不知Java老程序员如何感受，就我而言，我更喜欢不断更新，虽然最近更新确实有点频繁了。 当然除了语法特性的改变意外，还有很多底层结构的改进，当然这才是其核心。例如类库发展、模块化管理、安全特性与补丁、新的JVM GC、脚本化、黑匣子(JFR)等。 试试不？Java 9 和 10 简直就是一闪而过，印象中好像就一两个小版本号，而Java 11 不同了，它可是LTS。Oracle官方承诺对其会有持续的update更新。同时大家深爱的Java 8马上就要不更新了，所以这次真的可以尝试进行JDK企业级切换了。 个人感觉Java 每半年更新的方式，看来要止住其语言发展的颓势，重新崛起了。Java作为主要的开发语言还是值得大家技术投入的。小伙伴们跟上这波更新吧。后面我也希望多尝试JDK新的开发特性。 你的感觉呢？ 参考网站 infoq]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Restart]]></title>
    <url>%2F2018%2F09%2F26%2Fnote%2F</url>
    <content type="text"><![CDATA[尝试重新开始尝试重启这个blog，因为有越来越多的文字需要记录，也想分享，而在github上的README.md文件中写又显然不合适。所以重新启用这个工程开始整理自己的随笔。 同时，几个月前开始更新自己的github工程，主要围绕三个项目： Java Tech Java相关技术 Python Tech Python相关技术 CICD Tech CI/CD DEV/OPS相关技术 维护这三个工程主要目的在于： 帮助自己总结所学，时间长了很容已忘记 本人使用的技术绝大部分本来就是公开的，也希望今后可以帮到其他人。 所以在所有项目或者示例代码中，我尽可能说明详细，并给出我所引用的原地址而还是有很多思路上的内容需要记录下来，所以想在这里记录，此blog也将围绕我的技术领域展开。 为何重新开始作为计算机开发工程师，本人离吴军老师所定义的四级工程师水平（详见谷歌来信中的定义）还有不少差距，而我希望可以做到。唯一的方法是不断积累。这里的重新开始是给自己设定了一个目标，一个改变自己的目标，重新开始向新的目标前进。 祝所有工程师好运！]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>others</tag>
      </tags>
  </entry>
</search>
