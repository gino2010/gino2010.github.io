<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Distributed Lock]]></title>
    <url>%2F2018%2F10%2F22%2Fdistributed-lock%2F</url>
    <content type="text"><![CDATA[分布式锁，在微服务，多服务器水平扩展以及高并发的场景下，要保证共享资源正确处理，这个锁很重要。我了解到了三种实现方式： 数据库方式，基于主键唯一性约束或行级锁实现 Zookeeper实现，基于其临时有序节点实现 Redis方式，基于setNX操作实现 三种方式各有优缺点，在恢复此博客之前我已经实现了基于Redis版本的分布式锁，现在把另外两种加以实现，并做相应的对比。 Mysql数据库方式实现分布式锁，主要用三种形式： 乐观锁，version，通过where条件中的version决定是否可以更新成功，从而获得锁 主键唯一约束方式，是否可以正常写入数据，从而获得锁 数据库自身锁 for update 来决定是否可以获得锁 这里我们不讨论乐观锁，为了和zookeeper、redis的锁做对比，这里采用使用主键唯一约束方式实现锁。 创建锁表，其中method_name需要索引并唯一，时间默认1234567CREATE TABLE method_lock( id int PRIMARY KEY NOT NULL AUTO_INCREMENT, method_name varchar(64) NOT NULL, update_time timestamp not null default current_timestamp on update current_timestamp);CREATE UNIQUE INDEX method_lock_method_name_uindex ON method_lock (method_name); 关闭自动提交，开始手动提交，保证事务中的操作原子性1connection.setAutoCommit(false); 获得锁，两个操作，删除超时的锁（超时自动释放机制），插入数据获得锁123456789PreparedStatement preparedDelete = MySQLConfig.connection.prepareStatement(clearSQL);preparedDelete.setString(1, name);preparedDelete.setInt(2, 3);preparedDelete.executeUpdate();PreparedStatement preparedInsert = MySQLConfig.connection.prepareStatement(insertSQL);preparedInsert.setString(1, name);MySQLConfig.connection.commit(); 如果提交失败，进行重试，设定时间间隔和重试次数1public static boolean getLockTimes(String name, int times, int interval) 释放锁，直接删除锁占有的记录1234PreparedStatement preparedDelete = MySQLConfig.connection.prepareStatement(deleteSQL);preparedDelete.setString(1, name);preparedDelete.executeUpdate();MySQLConfig.connection.commit(); Zookeeper不重复造轮子了，轮子原理简单说一下吧，两种实现方式： 固定节点，利用文件名称唯一性，谁可以创建create指令该节点，谁就获得锁，类似redis中的获取锁操作，删除节点释放锁，其它watch该节点 利用zookeeper中临时有序节点，尝试获得锁，如果当前线程申请到的节点序号为最小，则获得锁，否则监听前一个序号等待状态改变，然后再次判断。 建议大家，如果有轮子就不要自己造了，因为绝大多数情况下，我们造的不如已有的轮子。所以，实验使用成熟的CuratorFramework，创建InterProcessMutex锁对象 通过acquire尝试获得锁，其中3s为可以接受的尝试获得锁的时间，如果太短，可能资源竞争激烈导致获得不到锁，而返回false，所以考虑了重试机制。1mutex.acquire(3, TimeUnit.SECONDS); 释放锁，事务处理完毕后，需要释放锁，最好判断一下，是不是当前线程拥有这个锁，然后尝试释放。1234if (mutex.isOwnedByCurrentThread()) &#123; mutex.release(); log.info("release lock....");&#125; 如果按照网上原理介绍来看，其判断是自增序号的最小值为获得锁，那么其应该是是一个公平锁，这一点我需要再进一步验证一下。 RedisRedis分布式锁，redis官网有相应的文章阐述，这里相当于模仿着造了一个轮子 首先实现一个redis实例即单节点的例子，这个是基础。通过多线程方式模拟测试，实际应用不应该是多线程环境，否则使用线程同步相关技术就好了。其次，初步实现了RedLock方式，用于多个Redis节点，增强其稳定性。但实际使用可能还是单节点比较多，需要考虑锁失效的弥补方式。 这里的set方法是关键，其保证了判断是否存在以及设置锁值和有效时间一系列操作的原子性，否则这个分布式锁的实现是不成立的。123456String res = resource.set(lockKey, uuid, "NX", "PX", keyExpire);if ("OK".equals(res)) &#123; resource.close(); log.info("Get lock, uuid: &#123;&#125;", uuid); return uuid;&#125; 设置成功，则获得锁，否则失败。其中设置的值为uuid随机数，所以这个理论上是非公平锁 释放锁，即删除值，这是需要watch这个值，并在事务内将其删除12345678910111213resource.watch(lockKey);if (uuid.equals(resource.get(lockKey))) &#123; Transaction multi = resource.multi(); Response&lt;Long&gt; del = multi.del(lockKey); multi.exec(); if (del.get() == 1) &#123; log.info("Release lock, uuid: &#123;&#125;", uuid); retFlag = true; &#125; else &#123; log.info("Release lock, failed!"); &#125; multi.close();&#125; 当redis有多个节点时，我们需要奇数个点来按照多数原则判断是否获得了锁。程序中通过一个redis中的不通DB来模拟的。有效时间内，节点数大于一半，就认为获得成功，否则失败12345678if ((passNode.get() &gt;= nodes / 2 + 1) &amp;&amp; (end - start) &lt; keyExpire) &#123; log.info("Get RedLock uuid &#123;&#125;, pass node:&#123;&#125;", uuid, passNode.get()); return uuid;&#125; else &#123; log.info("Get RedLock failed"); releaseLock(lockName, uuid); return null;&#125; 总结无论什么怎样实现分布式锁，都需要考虑一下内容： 判断锁是否存在和设置锁值，两步需要原子性 考虑申请锁时，申请的超时时间和尝试次数，具备非阻塞特性 需要考虑锁的正常销毁方式，主动删除锁 需要考虑锁的异常销毁方式，例如有效时间或者回话断开删除 适当考虑重入特性 使用总结： mysql 利用数据库特性还是很方便的，性能有限 zookeeper实现应该是非常严谨的，但是性能一般 Redis虽然实现上还存在争议，但是性能很好 性能: 缓存 &gt; Zookeeper &gt; 数据库可靠性: Zookeeper &gt; 缓存 &gt; 数据库 实现复杂度，看你对谁熟悉了，我个人感觉得差不多。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>mysql</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper]]></title>
    <url>%2F2018%2F10%2F18%2Fzookeeper%2F</url>
    <content type="text"><![CDATA[近期在做MQ的实验，所以又接触了一下Zookeeper，之所说又是因为之前碰到过，但是只是用而已没有了解过一些细节。 Zookeeper 做什么？引用官方原话：ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. 他可以提供高可靠的分布式协调服务，包括中心化配置服务等。之前我用它做了什么，注册发现服务器，你是不是也是用了这个功能，但是具体怎么实现的，Spring Cloud都已经实现了，没有深入关心过。 这个文章我们补一些必要的知识，更加深入的了解Zookeeper。 Zookeeper 怎么玩？首先，简单说他好似一个文件目录，是一个可以存储数据的服务器，这里我们先忽略其集群中的一些特性（选举制度等），我们看它对外可以提供什么。 它内部有类似文件目录的结构，节点称之为znode 文件结构可以存储数据，可以想象为目录结构的Redis 节点数据大小有限，不可以超过1M 可以通过接口获得数据，这也是我们用其分布式协调服务的关键 补充，数据过大怎么办，目前了解到的有两个思路，没有实验过： 使用专业的分布式存储HDFS等 使用Redis，然后zookeeper记录索引就好了 命令行两种形式，分别对应查看管理 服务器状态和内部存储。 查看管理服务器状态，可以通过telnet 和 nc发出指令，一般使用nc比较方便（具体命令参考网上信息）1234567891011echo stat| nc 127.0.0.1 2181 # 来查看哪个节点被选择作为follower或者leaderecho ruok| nc 127.0.0.1 2181 # 测试是否启动了该Server，若回复imok表示已经启动。echo dump| nc 127.0.0.1 2181 # 列出未经处理的会话和临时节点。echo kill | nc 127.0.0.1 2181 # 关掉serverecho conf | nc 127.0.0.1 2181 # 输出相关服务配置的详细信息。echo cons | nc 127.0.0.1 2181 # 列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。echo envi | nc 127.0.0.1 2181 # 输出关于服务环境的详细信息（区别于 conf 命令）。echo reqs | nc 127.0.0.1 2181 # 列出未经处理的请求。echo wchs | nc 127.0.0.1 2181 # 列出服务器 watch 的详细信息。echo wchc | nc 127.0.0.1 2181 # 通过 session 列出服务器 watch 的详细信息，它的输出是一个与 watch 相关的会话的列表。echo wchp | nc 127.0.0.1 2181 # 通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径。 如果提示：xxx is not executed because it is not in the whitelist.请在conf/zoo.cfg中添加：14lw.commands.whitelist=* #或者具体指令stat, ruok 查看管理服务中的节点信息，需要zkCli命令（客户端），这个在zookeeper所对应的bin目录下有，zkCli进入后，随便敲点啥，你可以看到如下：1234567891011121314151617181920212223242526272829[zk: localhost:2181(CONNECTED) 0] ?ZooKeeper -server host:port cmd args addauth scheme auth close config [-c] [-w] [-s] connect host:port create [-s] [-e] [-c] [-t ttl] path [data] [acl] delete [-v version] path deleteall path delquota [-n|-b] path get [-s] [-w] path getAcl [-s] path history listquota path ls [-s] [-w] [-R] path ls2 path [watch] printwatches on|off quit reconfig [-s] [-v version] [[-file path] | [-members serverID=host:port1:port2;port3[,...]*]] | [-add serverId=host:port1:port2;port3[,...]]* [-remove serverId[,...]*] redo cmdno removewatches path [-c|-d|-a] [-l] rmr path set [-s] [-v version] path data setAcl [-s] [-v version] path acl setquota -n|-b val path stat [-w] path sync pathCommand not found: Command not found ?[zk: localhost:2181(CONNECTED) 1] 我主要使用了： ls 显示znode crate 创建znode，并设置初始内容 get 获取znode内容 set 修改znode内容 delete 删除znode 退出客户端： quit 实验工程测试工程地址 ，开发环境： mac os x &amp; idea &amp; gradle spring cloud &amp; zookeeper config &amp; discovery zookeeper 3.5 in docker 请注意，其中使用的最新版的curator包只支持zookeeper3.5 关键代码通过CuratorFramework 设置或读取zookeeper中的节点123456789curatorFramework.blockUntilConnected();Stat stat = curatorFramework.checkExists().forPath("/test");if(stat==null) &#123; curatorFramework.create().creatingParentsIfNeeded() .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) .forPath("/test", "data".getBytes());&#125;byte[] bytes = curatorFramework.getData().forPath("/test");log.info("path test:&#123;&#125;", new String(bytes)); 将zookeeper作为配置中心，通过value注解获取zookeeper中的配置信息，这样可以做到在不重新启动服务的情况下，动态加载配置信息代码需要： 12@Value("$&#123;zc&#125;")private String zc; 也可以将配置信息加载到一个对象上，并实现动态刷新123456789@Component@RefreshScope@ConfigurationProperties("demopro")public class DemoProperties &#123; private String key; private String value; //get set&#125; 配置文件需要： 12345678application: name: zookeeperDemo config: enabled: true root: /demo defaultContext: context profileSeparator: ',' 因为spring cloud支持active profile，所以对应的zookeeper的znode路径可以是： /demo/zookeeperDemo,default /demo/zookeeperDemo /demo/context,default /demo/context 具体到zc这个配置，对应在default下的全路径是：/demo/zookeeperDemo,default/zc，你可以在zookeeper中创建一个： 1create /demo/zookeeperDemo,default/zc data 具体到DemoProperties配置对应在default下的全路径是：12create /demo/zookeeperDemo,default/demopro.key prokeycreate /demo/zookeeperDemo,default/demopro.value provalue 以上为工程实验的关键点，具体工程参考源码，工程后续可能还会更新。 吐槽这些问题不是针对zookeeper，只是借此表达一下，其它国内实例代码也有类似的普遍现象 Curator的使用，国内几乎没有，说明大家几乎没有尝试自己去使用zookeeper的存储功能，都是人云亦云般的介绍功能 查看中心化配置，路径的写法几乎都没有验证，实例代码几乎都不起作用，你们贴别人代码时不实验一下吗？ 请大家（同行）做到，我写的，我贴的，我抄的代码，我至少都实验过，不要传播错误的代码。共勉！]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Message Queue 初探]]></title>
    <url>%2F2018%2F10%2F16%2Fmq%2F</url>
    <content type="text"><![CDATA[消息队列（MQ），平时经常遇到的中间件技术。个人工作中已经使用的RabbitMQ，最近开始使用Kafka，因此也打算把ActiveMQ实验一下。所以本文章将围绕这三个MQ产品进行相应的实验。 创建实验工程三个MQ实验工程地址 工程使用spring boot创建，所有实现都将基于spring全家桶，已经很完毕了，拿来直接用吧。 为了后续实验方便，分别多个mq的producer和consumer工程 使用gradle管理项目结构 使用docker搭建测试所需要的服务器，文件可以参考，实际部署环境有所调整 Kafka首先实验了Kafka的生产和消费基本代码procuder：1this.kafkaTemplate.send(topic, message); consumer:1@KafkaListener(topics = "$&#123;app.topic&#125;") 运行说明 使用三个kafka broker 节点，使用docker-compose对应的service实现 创建topic，使用三个分区和两个副本 使用idea，运行工程，配置多个运行实例 特性总结 一个分区对应一个消费者 一个分区内消息顺序消费 分区和和服务器应该成倍数关系，保证分区均匀分布 副本数量应该小于服务器数量，当可用分区失效时，从副本中选出leader，成为新的可用分区 节点高可用性，消费服务瞬间切换 保存近期所有数据，通过offset可以获得任意位置的消息 是否允许自动创建topic需要在kafka中配置 ACK MODE 和 Commit需要注意ack mode和 commit，此项影响数据的刷盘机制。根据实际情况选择 RECORD 逐笔ack并提交 BATCH 一个poll周期进行ack提交 TIME 通过设置ackTime定时提交 COUNT 通过设置ackCount累计数量提交 COUNT_TIME 同上组合，哪个复合执行哪个 MANUAL 手动方式生成ack，批量提交 MANUAL_IMMEDIATE 手动方式生成ack并立即提交 广播与点对点广播有时也叫pub和sub，就是一个topic，多个订阅者。每个订阅者都会收到相同的消息，消息被多次消费。点对点，一个topic中的消息对应一个消费者，消息只会被消费一次 在Kafka的系统中，如何区分以上两种方式，是通过consumer group实现的。 多个消费者在一个consumer group中，那么他们就是一个消费整体，消息只会被一个具体的消费者消费一次如果想多个同时消费，那么需要多个consumer group。这样来看consumer group需要与具体服务对应，一般一个独立的服务需要消费一次消息。 总的来说，体会到了大家喜欢的它原因，具体一些实验后续将深入。 ActiveMQ每个MQ中的术语大同小异，但又十分不统一，让我们看看ActiveMQ Queue 和 TopicTopicsIn JMS a Topic implements publish and subscribe semantics. When you publish a message it goes to all the subscribers who are interested - so zero to many subscribers will receive a copy of the message. Only subscribers who had an active subscription at the time the broker receives the message will get a copy of the message. QueuesA JMS Queue implements load balancer semantics. A single message will be received by exactly one consumer. If there are no consumers available at the time the message is sent it will be kept until a consumer is available that can process the message. If a consumer receives a message and does not acknowledge it before closing then the message will be redelivered to another consumer. A queue can have many consumers with messages load balanced across the available consumers. 这里的 topics 类似kafka中的广播，pub sub 模式，queue是队列是点对点模式。他的主要区别是，消费方式的确定不是在consumer设置，而是在MQ Server中设置消费性质上同上： topic的消息会多个消费者同时消费，但并不做消息堆积，没有之前的消息 queue消息只有一个消费者消费，并做消息缓存堆积，直到消费为止 同时queue的消费者是负责均衡的会分摊消息队列的中的数据，但是不能保证按顺序执行 关键代码消费端1234567891011121314151617@Beanpublic JmsListenerContainerFactory&lt;?&gt; queueListenerFactory(ConnectionFactory connectionFactory, DefaultJmsListenerContainerFactoryConfigurer configurer) &#123; DefaultJmsListenerContainerFactory factory = new DefaultJmsListenerContainerFactory(); configurer.configure(factory, connectionFactory); return factory;&#125;@Beanpublic JmsListenerContainerFactory&lt;?&gt; topicListenerFactory(ConnectionFactory connectionFactory, DefaultJmsListenerContainerFactoryConfigurer configurer) &#123; DefaultJmsListenerContainerFactory factory = new DefaultJmsListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); configurer.configure(factory, connectionFactory); factory.setPubSubDomain(true); return factory;&#125; 通过spring boot 配置文件可以指明消费方式，是topic还是queue，但是只能只一种。为了同时支持两种方式，我么需要声明JmsListenerContainerFactory。是否开启pub sub domain，决定是queue还是topic1factory.setPubSubDomain(true); 同时配合JmsListener注解，就可以指明消费方式了。如果指明的消费方式与ActiveMQ所创建的queue或topic不一致，则消息不能正常消费。1@JmsListener(destination = "$&#123;app.queue&#125;", containerFactory = "queueListenerFactory") 生产端123456789@Bean public Queue queue() &#123; return new ActiveMQQueue(queueName); &#125; @Bean public Topic topic() &#123; return new ActiveMQTopic(topicName); &#125; 通过不通类型指明是topic还是queue 运行说明同样创建多个运行实例，来观察消费情况 观察ActiveMQ管理后台，你可以看到相关的配置信息 特性总结 简单，两种消费模式非常清晰，没有复杂的系统结构 自带管理后台还算好用 还需要深入体会其一些参数设置，初步感觉中规中矩没有什么好说的。😜 RabbitMQ最后说熟悉的RabbitMQ吧。我很喜欢RabbitMQ，功能上丰富，性能不错，相比ActiveMQ，我更喜欢RabbitMQ吧。当然具体使用，还是要分应用场景。 基本概念RabbitMQ中有几个主要概念，和其它MQ的定义有些区别 Exchange 交换机，用于消息的分发，如果不指定则会使用默认的 Queue 队列，实际缓存数据的消息队列，可对应多个消费者 Topic 主题，消息可以有主题，用于exchange分配消息是的判断依据 virtual host 虚拟路径，可以创建虚拟路径将相关配置分开并设定特定用户用于访问控制 消费方式RabiitMQ的消费方式和灵活度上应该是这三者中最好的，并且官方给出了详细的实例说明，超有爱❤️当然由于模式多，它也就是最复杂的。官方给出的六个实例，这里简单说一下，具体代码看原址 Hello World 最普通的生产消费代码 Work Queue 默认exchange，工作队列，一个队列被多个消费者消费，且一个消息只消费一次 Publish/Subscribe 发布订阅，通过exchange Fanout模式进行队列分发，实现一条消息可以被多个消费者消费 Routing 路由方式，通过exchange和routing key指定消息路由到具体的队列别特定的消费者消费 Topics 主题方式，通过exchange和topic比配规则指定消息路由到具体的队列别特定的消费者消费 RPC 通过消息队列实现RPC调用过程 关键代码生产端123456789101112131415// 声明queue@Beanpublic Queue queue() &#123; return new Queue(queueName);&#125;// 声明fanout exchange@Beanpublic FanoutExchange exchange() &#123; return new FanoutExchange(broadcast, false, true);&#125;// 声明 queue与exchange的绑定关系@BeanBinding binding1(Queue queueBroadone, FanoutExchange exchange) &#123; return BindingBuilder.bind(queueBroadone).to(exchange);&#125; 消费端1234@RabbitListener(queues = "$&#123;app.broadone&#125;")public void recevieOne(String message) &#123; log.info("consumer receive broadcast one: &#123;&#125;", message);&#125; 运行说明这里我只做消息在多消费者下顺序消费观察和广播观察，其它实例参考官网代码吧，没有必要重复了。 一个生产者、一个queue、多个消费者，和ActiveMQ queue方式，观察效果一致： 多个消费者的消息分摊，如果每条消费执行时间差异较大，消费顺序不保证一致 消费退出，另一个消费者会接替未完成的消息工作 广播消息默认堆积，其本质还是消费队列，不能多个消费者消费一个queue实现pub/sub 同样创建多个运行实例，来观察消费情况 管理后台可以看到的信息 特性总结 功能多，使用灵活 AMQP，性能不错 管理后台方便 实验总结 如果你需要消息顺序消费、分布式存储的高可用性，指定消息位置再次消费，较高的吞吐 —— Kafka 如果你要消息正常消费，无顺序要求、无特殊路由要求。广播消费时，多个消费者可以监听一个queue的方式完成 —— ActiveMQ 如果你要适合多种消息根据自定义规则（通配符等）路由道不同的消息队列，或兼容不通场景，希望广播消息有堆积不丢失 —— RabbitMQ 以上MQ都还有很多配置参数应对不通的应用需求，可能通过配置实现默认不支持的功能，具体使用情况，如果以后遇到我再单独说明。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>middleware</tag>
        <tag>Kafka</tag>
        <tag>ActiveMQ</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack 从入门到继续]]></title>
    <url>%2F2018%2F10%2F11%2Fopenstack%2F</url>
    <content type="text"><![CDATA[近期给自己挖的技术坑有点多，我忍不住再挖一个，最近又了解到了云服务的相关技术（算是技术储备吧） What is OpenStack?OpenStack是被广泛使用的云操作系统，它管啥，如图： Components所有组件详见：网站列出的所有组件 找几个介绍多的，简单说一下 HORIZON前端Web管理界面，包括Dashboard控件展示，便于用户对相关服务进行操作 NOVA计算服务,应该是管理计算资源的组件，提供相应的管理服务 NEUTRON提供云计算的网络虚拟化技术，为OpenStack其他服务提供网络连接服务，实现SDN SWIFTSwift是高可用、分布式、最终一致性的对象存储，具体文件对象 CINDER块存储服务，更像是硬盘，数据卷 KEYSTONE认证服务，支持LDAP Oauth OpenID等 GLANCE镜像服务，不通的操作系统镜像 HEAT编排架构资源 不通场景中需要不通的服务来构建，可以参考sample configurations What is the relationship between Docker and OpenStack Docker 主要针对 Paas 平台，是以应用为中心。 OpenStack 主要针对 Iaas 平台，以资源为中心，可以为上层的 PaaS 平台提供存储、网络、计算等资源。 这个话题先开个头，后面有机会再继续深入吧。]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>openstack</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的OKR(2018.10)]]></title>
    <url>%2F2018%2F09%2F29%2Fokr%2F</url>
    <content type="text"><![CDATA[最近重温吴军老师的硅谷来信，想起了Google人员采用的目标管理方法OKR(Objectives and Key Results)全称为“目标和关键成果”。吴军老师在其硅谷来信114封信中分享了这个方法（不仅可以用于工作也可以用于自己的生活）并结合他个人的2017年目标做了阐述。这也使我产生了同样念头，用OKR方式管理我自己的目标。 初衷和理解我希望我可以不断进步，可以用更为有效方式使自己获得成长，而对OKR目标管理初步了解下来，我认为是合适我的想法。 OKR的目标制定一般是需要一些挑战性的，这样才能达到自我提升的目的，我也将逐步加大目标达成的难度，同时开始也可能会有些设定不合理。 其次，目标不能太多，否则难以集中注意力，一般在5个以内。 时间不易太长或太短，太短难以实现有挑战性的目标。太长过程有可能有太多不确定性的事情打破原有的计划，使得制定意义减弱。所以借鉴Google的做法，制定季度OKR。 季度 OKR正好九月底了，10月开始正好是2018年最后一个季度，也将是我的第一个OKR季度。 目标一 英语流利说学习达标近期参加了英语流利说付费课程，提升自己的口语能力，也是近期主要的学习内容。 连续打卡，每天学习时间平均不低于70分钟 所有课程分数不低于3颗星🌟（满星4颗） 流利说评定的口语等级上升一级。（按照当前进度应该可以做到） 除此之外，我还在得到APP上购买了《吴军的谷歌方法论》和《香帅的北大金融学课》这个学习也会保持，但这个基本没有什么挑战了。 目标二 深入一个计算机中的流行技术学习掌握并深入一个流行的计算机技术 深入了解和掌握 Kubernets 这是我最近最想掌握的一个技术。除此之外我还会不定期更新个人github中的一些小例子，来记录我零碎的技术总结。 目标三 看完一本非计算机类书我的书单已经列了很久、很多了，是需要花些时间看看书了 看完赫拉利的《今日简史》，看看都提出了什么问题 因为时间原因，这个目标可能最难完成。之前把赫拉利的《人类简史》看完了，《未来简史》看了一部分，看不下去了，再找时间吧。而《今日简史》中的当今问题使我比较感兴趣的，想读读，也算是把赫拉利的著作都看了看。题外话，近半年还看了两个小说《副本》和《头号玩家》这两个都有对应的影视作品，感兴趣的朋友可以看看，纯当消遣。 目标四 锻炼身体，保持身体健康天气转凉，终于可以锻炼身体了，天气热时真的是懒得动，极爱出汗的我更喜欢冬天。 每周用Keep（一个健身APP）不少于2次， 每周 跑步不小于3公里（我知道这个目标定低了一些，我需要先适应一下） 每日睡眠（包含午休）不少于7个小时。 这个估计难度也不小，我可以支配的时间太有限了，现在晚上睡眠平均小于6小时，很少运动，这是我精力有些疲倦，所以需要改变一下。 目标五 陪孩子Family is first，我一直提醒自己，孩子又是其中最关键的。 每日至少用半个小时与孩子做有效沟通，了解一天的情况或讨论一个小事情 平均每周用完整的3个小时陪孩子做些有意义或者有趣的事情，包含户外活动等。 五个目标，不多不少，希望可以在下面一个季度都可以做到。 年度 OKR索性再列几个年度的OKR吧，希望后面一年可以做到 目标一 付费课程学习 购买付费课程，全年不少于三门，并完成学习内容 目标二 读书 读非计算机类、非小说类书，全年不少于5本。 目标三 英语口语 完成流利说口语付费课程内容 按照流利说标准，达到Level 6级或以上 当然还有工作上的一些目标，这里就详述了。 列出这些和大家分享，同时也是督促自己，如果你也感兴趣，不妨试试。如有好的建议和想法欢迎留言，谢谢！ I wanna improve myself, better late than never. OKR参考文章]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>OKR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 11]]></title>
    <url>%2F2018%2F09%2F27%2FJava-11%2F</url>
    <content type="text"><![CDATA[昨天得知Java 11发布。请允许我说：我的天啊，竟然Java 11了。 连Java 8还没有完全熟练使用的我，一时间有点恍惚。 近期，Java更新如此频繁，让人有点应接不暇，新的features层出不穷，而我们又真的学习使用了几个呢？ 反正我只用了一小部分吧。这里不列举Java 8之后各个版本中的features了，大家可以自行Google。 这里只想说：Java作为生命力极强的大型服务类开发语言，Oracle好像在给其注入新的活力，也在打破Java原有的墨守陈规。我们可以看出它的很多新特性是源于这个时代技术的发展，也有很多借鉴了其它语言的特性，在”提(da)升(po)”原有的语法结构方式给用户带来新的开发体验。这也是在满足新加入Java世界的开发者？ 不知Java老程序员如何感受，就我而言，我更喜欢不断更新，虽然最近更新确实有点频繁了。 当然除了语法特性的改变意外，还有很多底层结构的改进，当然这才是其核心。例如类库发展、模块化管理、安全特性与补丁、新的JVM GC、脚本化、黑匣子(JFR)等。 试试不？Java 9 和 10 简直就是一闪而过，印象中好像就一两个小版本号，而Java 11 不同了，它可是LTS。Oracle官方承诺对其会有持续的update更新。同时大家深爱的Java 8马上就要不更新了，所以这次真的可以尝试进行JDK企业级切换了。 个人感觉Java 每半年更新的方式，看来要止住其语言发展的颓势，重新崛起了。Java作为主要的开发语言还是值得大家技术投入的。小伙伴们跟上这波更新吧。后面我也希望多尝试JDK新的开发特性。 你的感觉呢？ 参考网站 infoq]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Restart]]></title>
    <url>%2F2018%2F09%2F26%2Fnote%2F</url>
    <content type="text"><![CDATA[尝试重新开始尝试重启这个blog，因为有越来越多的文字需要记录，也想分享，而在github上的README.md文件中写又显然不合适。所以重新启用这个工程开始整理自己的随笔。 同时，几个月前开始更新自己的github工程，主要围绕三个项目： Java Tech Java相关技术 Python Tech Python相关技术 CICD Tech CI/CD DEV/OPS相关技术 维护这三个工程主要目的在于： 帮助自己总结所学，时间长了很容已忘记 本人使用的技术绝大部分本来就是公开的，也希望今后可以帮到其他人。 所以在所有项目或者示例代码中，我尽可能说明详细，并给出我所引用的原地址而还是有很多思路上的内容需要记录下来，所以想在这里记录，此blog也将围绕我的技术领域展开。 为何重新开始作为计算机开发工程师，本人离吴军老师所定义的四级工程师水平（详见谷歌来信中的定义）还有不少差距，而我希望可以做到。唯一的方法是不断积累。这里的重新开始是给自己设定了一个目标，一个改变自己的目标，重新开始向新的目标前进。 祝所有工程师好运！]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>others</tag>
      </tags>
  </entry>
</search>
